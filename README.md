# CLF04 â€” Classification de biens de consommation

[![Python](https://img.shields.io/badge/Python-3.11+-blue.svg)](https://www.python.org/)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.28+-red.svg)](https://streamlit.io/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.100+-green.svg)](https://fastapi.tiangolo.com/)
[![Accuracy](https://img.shields.io/badge/Accuracy-90.59%25-brightgreen.svg)](/)

## ðŸ“‹ Vue d'ensemble

Ce projet implÃ©mente un systÃ¨me de classification automatique pour catÃ©goriser des biens de consommation e-commerce Ã  partir de donnÃ©es textuelles (nom, description, marque). L'objectif est d'automatiser l'attribution des produits Ã  des catÃ©gories pour optimiser l'expÃ©rience utilisateur sur une marketplace anglophone.

**ðŸŽ¯ Performance actuelle :** 90.59% d'accuracy sur 56 catÃ©gories (aprÃ¨s optimisation)

## ðŸ“‘ Table des matiÃ¨res

- [Architecture du projet](#ï¸-architecture-du-projet)
- [Structure du projet](#-structure-du-projet)
- [DÃ©marrage rapide](#-dÃ©marrage-rapide)
- [Dataset](#-dataset)
- [Workflow et mÃ©thodologie](#-workflow-et-mÃ©thodologie)
- [RÃ©sultats et performances](#-rÃ©sultats-et-performances)
- [DÃ©ploiement](#-dÃ©ploiement)
- [Notes techniques](#-notes-techniques)
- [Livrables du projet](#-livrables-du-projet)

## ðŸ—ï¸ Architecture du projet

Le projet comprend :
- **Notebook Jupyter** pour l'analyse exploratoire et le prototypage
- **Script d'entraÃ®nement optimisÃ©** avec feature engineering avancÃ©
- **API REST (FastAPI)** pour l'intÃ©gration backend
- **Interface web (Streamlit)** pour les dÃ©monstrations

## ðŸ“‚ Structure du projet

```
soutenance/
â”œâ”€â”€ classification_biens_consommation.ipynb    # Notebook principal d'analyse
â”œâ”€â”€ subject.md                                  # Ã‰noncÃ© du projet
â”œâ”€â”€ README.md                                   # Cette documentation
â”œâ”€â”€ .gitignore                                  # Fichiers Ã  exclure du versioning
â”‚
â”œâ”€â”€ api/                                        # API REST FastAPI
â”‚   â”œâ”€â”€ api_app.py                             # Application FastAPI
â”‚   â”œâ”€â”€ client_example.py                      # Exemple client Python
â”‚   â”œâ”€â”€ test_api.py                            # Tests automatisÃ©s
â”‚   â”œâ”€â”€ requirements.txt                       # DÃ©pendances API
â”‚   â”œâ”€â”€ run.sh                                 # Script de lancement
â”‚   â”œâ”€â”€ Dockerfile                             # Configuration Docker
â”‚   â”œâ”€â”€ Procfile                               # Configuration Heroku
â”‚   â”œâ”€â”€ QUICKSTART.md                          # Guide rapide
â”‚   â””â”€â”€ README.md                              # Documentation API
â”‚
â”œâ”€â”€ app/                                        # Interface Streamlit
â”‚   â”œâ”€â”€ streamlit_app.py                       # Application Streamlit
â”‚   â”œâ”€â”€ test_models.py                         # Tests de chargement
â”‚   â”œâ”€â”€ test_app.py                            # Tests de l'interface
â”‚   â”œâ”€â”€ requirements.txt                       # DÃ©pendances app
â”‚   â”œâ”€â”€ run.sh                                 # Script de lancement
â”‚   â”œâ”€â”€ Procfile                               # Configuration Heroku
â”‚   â”œâ”€â”€ USAGE.md                               # Guide d'utilisation
â”‚   â”œâ”€â”€ CHANGELOG.md                           # Historique des changements
â”‚   â””â”€â”€ README.md                              # Documentation app
â”‚
â”œâ”€â”€ data/                                       # DonnÃ©es (non versionnÃ©)
â”‚   â”œâ”€â”€ flipkart_com-ecommerce_sample_1050.csv # Dataset principal
â”‚   â””â”€â”€ Images/                                 # Images des produits (1050)
â”‚
â””â”€â”€ models/                                     # ModÃ¨les entraÃ®nÃ©s (non versionnÃ©)
    â”œâ”€â”€ optimized_model.pkl                    # ModÃ¨le principal (2.8 MB)
    â”œâ”€â”€ optimized_vectorizer.pkl               # Vectorizer TF-IDF (275 KB)
    â”œâ”€â”€ optimized_scaler.pkl                   # Scaler pour features numÃ©riques
    â”œâ”€â”€ optimized_brand_encoder.pkl            # Encodeur de marques
    â”œâ”€â”€ optimized_model_metadata.json          # MÃ©tadonnÃ©es du modÃ¨le
    â”œâ”€â”€ final_model.pkl                        # ModÃ¨le legacy (si disponible)
    â”œâ”€â”€ tfidf_vectorizer.pkl                   # Vectorizer legacy
    â””â”€â”€ label_encoder.pkl                      # Encodeur de labels
```

## ðŸš€ DÃ©marrage rapide

### PrÃ©requis
```bash
python >= 3.11
pip install -r requirements.txt
```

### Option 1 : Lancer l'application Streamlit (RecommandÃ©)

```bash
cd app
pip install -r requirements.txt
streamlit run streamlit_app.py
# Ou simplement : ./run.sh
```

AccÃ©dez Ã  l'interface sur **http://localhost:8501**

### Option 2 : Utiliser l'API REST

```bash
cd api
pip install -r requirements.txt
python api_app.py
# Ou : ./run.sh
```

Documentation interactive sur **http://localhost:8000/docs**

### Option 3 : Explorer le notebook

```bash
jupyter notebook classification_biens_consommation.ipynb
```

## ðŸ“Š Dataset

**Source :** Flipkart E-commerce  
**Taille :** 1050 produits  
**Classes :** 642 catÃ©gories initiales â†’ 56 classes retenues (â‰¥3 exemples)  
**Langue :** Anglais  

**Colonnes principales :**
- `product_name` : Nom du produit
- `description` : Description dÃ©taillÃ©e
- `brand` : Marque du produit
- `retail_price` : Prix de vente
- `discounted_price` : Prix aprÃ¨s remise
- `product_category_tree` : CatÃ©gorie (cible)
- `product_specifications` : SpÃ©cifications techniques
- `Images/` : Dossier contenant 1050 images produits

## ï¿½ Workflow et mÃ©thodologie

### 1. Configuration et chargement des donnÃ©es
- DÃ©finition des rÃ©pertoires de travail
- Import des bibliothÃ¨ques (pandas, scikit-learn, matplotlib)
- Chargement du dataset Flipkart (1050 produits, 642 catÃ©gories)

### 2. Analyse exploratoire (EDA)

**Nettoyage :**
- Suppression des colonnes non pertinentes : `uniq_id`, `crawl_timestamp`, `pid`
- Imputation des valeurs manquantes :
  - Prix : mÃ©diane
  - Brand : "NoBrand"
  - SpÃ©cifications : chaÃ®ne vide

**Visualisations :**
- Distributions univariÃ©es (histogrammes, boxplots)
- Distribution trÃ¨s dÃ©sÃ©quilibrÃ©e des catÃ©gories
- Analyses bivariÃ©es (prix vs catÃ©gories)

### 3. PrÃ©traitement et Feature Engineering

**Filtrage des classes rares (KEY IMPROVEMENT!) :**
- Seuil minimal : 3 exemples par classe
- 642 catÃ©gories â†’ 56 classes retenues
- 1050 Ã©chantillons â†’ 424 Ã©chantillons filtrÃ©s

**Split stratifiÃ© :**
- Train : 60% (254 Ã©chantillons)
- Validation : 20% (85 Ã©chantillons)
- Test : 20% (85 Ã©chantillons)

**Feature Engineering avancÃ© :**
1. **Texte combinÃ©** : product_name + description + brand + specifications
2. **Vectorisation TF-IDF** :
   - 10,000 features max
   - N-grams : (1, 3) pour capturer le contexte
   - min_df=2, max_df=0.8
   - sublinear_tf=True
   - Stop words anglais
   - RÃ©sultat : ~6,400 features textuelles

3. **Features numÃ©riques** :
   - Prix retail normalisÃ© (StandardScaler)
   - Taux de remise : (retail - discounted) / retail
   - Marque encodÃ©e (Top 50 + "Other")

4. **Combinaison finale** :
   - Matrice sparse : 6,439 features (6,436 texte + 3 numÃ©riques)

### 4. ModÃ©lisation optimisÃ©e

**ModÃ¨le baseline (version initiale) :**
- Logistic Regression simple
- TF-IDF 5000 features
- âŒ **RÃ©sultats :** Acc=19.05%, F1=7.17%

**ModÃ¨le optimisÃ© (version actuelle) :**
- **Algorithme :** Logistic Regression
- **HyperparamÃ¨tres :**
  - `class_weight='balanced'` (gÃ¨re le dÃ©sÃ©quilibre)
  - `C=1.0` (rÃ©gularisation)
  - `solver='lbfgs'`
  - `max_iter=1000`
  - `random_state=42`

**âœ… RÃ©sultats impressionnants :**
```
Validation : Acc=84.71% | F1=87.95%
Test :       Acc=90.59% | F1=90.78%

AmÃ©lioration vs baseline : +376% accuracy, +1,166% F1-score !
```

### 5. ClÃ©s du succÃ¨s

1. âœ… **Filtrage des classes rares** : Ã‰limine le bruit (642â†’56 classes)
2. âœ… **class_weight='balanced'** : Compense le dÃ©sÃ©quilibre rÃ©siduel
3. âœ… **TF-IDF enrichi** : 10k features + trigrams capturent mieux le contexte
4. âœ… **Features numÃ©riques** : Prix, remise, marque ajoutent de l'information
5. âœ… **Feature engineering robuste** : Combinaison texte + mÃ©tadonnÃ©es

### 6. Visualisations et mÃ©triques

- **Matrice de confusion** : Excellente diagonale
- **Rapport de classification dÃ©taillÃ©** : 
  - Precision/Recall/F1 par classe
  - Macro avg : 0.90
  - Weighted avg : 0.91
- **Distribution des classes** aprÃ¨s filtrage
- **Top-K prÃ©dictions** avec probabilitÃ©s

### 7. Sauvegarde des modÃ¨les

ModÃ¨les sauvegardÃ©s dans `/models/` :
- `optimized_model.pkl` (2.8 MB) - ModÃ¨le LogisticRegression entraÃ®nÃ©
- `optimized_vectorizer.pkl` (275 KB) - Vectorizer TF-IDF
- `optimized_scaler.pkl` - Scaler pour features numÃ©riques
- `optimized_brand_encoder.pkl` - Encodeur de marques
- `optimized_model_metadata.json` - MÃ©tadonnÃ©es et performances

## ðŸ“ˆ RÃ©sultats et performances

### Performance du modÃ¨le optimisÃ©

| MÃ©trique | Validation | Test |
|----------|-----------|------|
| **Accuracy** | 84.71% | **90.59%** |
| **F1-Score (macro)** | 87.95% | **90.78%** |
| **Precision (macro)** | - | 90% |
| **Recall (macro)** | - | 93% |

### AmÃ©lioration spectaculaire

| Version | Test Accuracy | Test F1 |
|---------|--------------|---------|
| **Baseline** (initiale) | 19.05% | 7.17% |
| **OptimisÃ©e** (actuelle) | **90.59%** | **90.78%** |
| **AmÃ©lioration** | **+376%** | **+1,166%** |

### Points forts

âœ… **Excellentes performances** : >90% sur test set  
âœ… **Pipeline complet** : De l'exploration Ã  la production  
âœ… **Feature engineering robuste** : Texte + mÃ©tadonnÃ©es + prix  
âœ… **Gestion du dÃ©sÃ©quilibre** : Filtrage + class_weight  
âœ… **Applications dÃ©ployables** : API REST + Interface web  
âœ… **Tests automatisÃ©s** : Validation du chargement des modÃ¨les  
âœ… **Documentation complÃ¨te** : README, QUICKSTART, guides  

### Pistes d'amÃ©lioration futures

**1. ModÃ¨les plus avancÃ©s :**
- Ensemble methods : Random Forest, XGBoost, CatBoost
- Deep Learning : LSTM, Transformers
- Embeddings prÃ©-entraÃ®nÃ©s : BERT, DistilBERT, Sentence-BERT

**2. Exploitation des images :**
- CNN pour features visuelles (ResNet, EfficientNet)
- Vision Transformers (ViT)
- ModÃ¨le multimodal texte + image

**3. Optimisation avancÃ©e :**
- Hyperparameter tuning (Bayesian Optimization, Optuna)
- Cross-validation stratifiÃ©e K-fold
- Ensembling (voting, stacking)

**4. Feature Engineering plus poussÃ© :**
- Analyse sÃ©mantique (word2vec, GloVe)
- Features de spÃ©cifications techniques
- Analyse de sentiment
- Extraction d'entitÃ©s nommÃ©es

**5. Monitoring et production :**
- A/B testing
- Monitoring des drifts de donnÃ©es
- Retraining automatique
- CI/CD pipeline
- Courbes ROC multiclasses
- Analyse des erreurs par catÃ©gorie

## ðŸŒ DÃ©ploiement

### API REST (FastAPI)

L'API FastAPI fournit une interface REST complÃ¨te pour la classification de produits.

**Lancement:**
```bash
cd api
python api_app.py
# OU utiliser le script
./run.sh
```

L'API sera disponible sur:
- **API**: http://localhost:8000
- **Documentation Swagger**: http://localhost:8000/docs
- **Documentation ReDoc**: http://localhost:8000/redoc

**Endpoints principaux:**

**GET** `/health` - VÃ©rification de l'Ã©tat de santÃ©
```bash
curl http://localhost:8000/health
```

**POST** `/predict` - PrÃ©diction complÃ¨te avec mÃ©tadonnÃ©es
```bash
curl -X POST "http://localhost:8000/predict" \
  -H "Content-Type: application/json" \
  -d '{
    "product_name": "Nike Running Shoes",
    "description": "Comfortable running shoes",
    "brand": "Nike"
  }'
```

**POST** `/predict/simple` - PrÃ©diction rapide (form data)
```bash
curl -X POST "http://localhost:8000/predict/simple" \
  -F "text=Nike running shoes for men"
```

**POST** `/batch-predict` - PrÃ©diction par lot
```bash
curl -X POST "http://localhost:8000/batch-predict" \
  -H "Content-Type: application/json" \
  -d '{
    "products": [
      {"description": "Nike shoes"},
      {"description": "Cotton bedsheet"}
    ],
    "top_k": 3
  }'
```

**GET** `/models/info` - Informations sur les modÃ¨les

**FonctionnalitÃ©s de l'API:**
- âœ… Documentation interactive (Swagger UI + ReDoc)
- âœ… Validation automatique des donnÃ©es (Pydantic)
- âœ… Gestion d'erreurs robuste
- âœ… Support CORS
- âœ… Logging dÃ©taillÃ©
- âœ… Cache des modÃ¨les en mÃ©moire
- âœ… Top-K prÃ©dictions avec probabilitÃ©s
- âœ… MÃ©tadonnÃ©es de performance
- âœ… PrÃ©dictions par lot
- âœ… Endpoints de monitoring

**Test de l'API:**
```bash
# Tests automatisÃ©s
cd api
python test_api.py

# Exemples avec curl
./examples.sh

# Client Python
python client_example.py
```

**DÃ©ploiement:**
- Docker: `docker build -t clf04-api . && docker run -p 8000:8000 clf04-api`
- Production: `gunicorn api_app:app -w 4 -k uvicorn.workers.UvicornWorker`
- Heroku: `git push heroku main` (Procfile configurÃ©)

### Interface Streamlit

L'application Streamlit offre une interface conviviale pour tester le modÃ¨le de classification.

**Lancement:**
```bash
cd app
streamlit run streamlit_app.py
# OU utiliser le script de lancement
./run.sh
```
L'interface s'ouvre automatiquement sur `http://localhost:8501`

**FonctionnalitÃ©s principales:**

**ðŸ“ Onglet Classification Textuelle:**
- Formulaire intuitif pour saisir le nom, description et marque du produit
- Exemples prÃ©dÃ©finis pour test rapide
- Affichage de la catÃ©gorie prÃ©dite avec niveau de confiance
- Top 5 des prÃ©dictions avec probabilitÃ©s
- Graphique interactif des rÃ©sultats
- Support pour texte en anglais

**ðŸ–¼ï¸ Onglet Classification par Image:**
- Upload d'images (JPG, JPEG, PNG)
- Extraction automatique de features avec ResNet50
- AperÃ§u de l'image tÃ©lÃ©chargÃ©e
- Exemples d'images du dataset
- Note: NÃ©cessite TensorFlow installÃ©

**â„¹ï¸ Onglet Ã€ propos:**
- Documentation du projet
- Statistiques et mÃ©triques
- Technologies utilisÃ©es
- Guide d'utilisation
- Roadmap des amÃ©liorations

**Interface:**
- Design moderne et responsive
- ThÃ¨me personnalisÃ© avec couleurs cohÃ©rentes
- Navigation par onglets
- Sidebar avec informations en temps rÃ©el
- Messages d'erreur explicites
- Mise en cache des modÃ¨les pour performances optimales

**Installation des dÃ©pendances:**
```bash
cd app
pip install -r requirements.txt
```

**DÃ©ploiement sur le cloud:**
- Streamlit Cloud: Push sur GitHub et dÃ©ployer via streamlit.io
- Heroku: Utiliser le `Procfile` fourni
- Docker: Container prÃªt Ã  l'emploi (voir app/README.md)

**Test du systÃ¨me:**
```bash
cd app
python test_models.py  # VÃ©rifie que les modÃ¨les sont chargÃ©s correctement
```

## ðŸ“ Notes techniques

**Dataset Flipkart E-commerce :**
- Source : Flipkart (marketplace indienne)
- Taille initiale : 1050 produits
- Classes initiales : 642 catÃ©gories distinctes
- **AprÃ¨s filtrage** : 424 produits, 56 catÃ©gories (â‰¥3 exemples)
- Langue : Anglais
- Images : 1050 images produits (dans `data/Images/`)

**Environnement de dÃ©veloppement :**
- Python 3.11+
- Jupyter Notebook pour exploration
- Anaconda/venv pour isolation
- Git pour versioning

**Technologies utilisÃ©es :**

| Composant | Technologies |
|-----------|-------------|
| **ML/Data Science** | scikit-learn, pandas, numpy |
| **Visualisation** | matplotlib, seaborn |
| **API REST** | FastAPI, uvicorn, pydantic |
| **Interface Web** | Streamlit |
| **Containerisation** | Docker (optionnel) |
| **Deployment** | Heroku, Streamlit Cloud |

**DÃ©pendances principales :**
```txt
# Core ML & Data
pandas>=2.0.0
numpy>=1.24.0
scikit-learn>=1.3.0
scipy>=1.11.0

# Visualisation
matplotlib>=3.7.0
seaborn>=0.12.0

# Web & API
streamlit>=1.28.0
fastapi>=0.100.0
uvicorn>=0.23.0
pydantic>=2.0.0

# Optionnel (pour classification image)
tensorflow>=2.16.0
pillow>=10.0.0
```

**Installation complÃ¨te :**
```bash
# 1. Cloner le repository
git clone <votre-repo>
cd soutenance

# 2. CrÃ©er un environnement virtuel
python -m venv .venv
source .venv/bin/activate  # Linux/Mac
# .venv\Scripts\activate  # Windows

# 3. Pour l'application Streamlit
cd app
pip install -r requirements.txt

# 4. Pour l'API FastAPI
cd ../api
pip install -r requirements.txt

# 5. Pour le notebook et l'entraÃ®nement
pip install jupyter pandas numpy scikit-learn matplotlib seaborn
```

**Structure des modÃ¨les sauvegardÃ©s :**
```
models/
â”œâ”€â”€ optimized_model.pkl              # 2.8 MB - LogisticRegression
â”œâ”€â”€ optimized_vectorizer.pkl         # 275 KB - TfidfVectorizer
â”œâ”€â”€ optimized_scaler.pkl             # <1 KB - StandardScaler
â”œâ”€â”€ optimized_brand_encoder.pkl      # <1 KB - LabelEncoder (marques)
â””â”€â”€ optimized_model_metadata.json    # MÃ©tadonnÃ©es (performances, configs)
```

## ðŸŽ“ Livrables du projet

Ce projet rÃ©pond aux objectifs du sujet CLF04 :

### âœ… Repository GitHub complet
- âœ… Notebook Jupyter avec analyse exploratoire complÃ¨te
- âœ… Scripts Python pour entraÃ®nement et dÃ©ploiement
- âœ… Extraction et traitement des donnÃ©es textuelles
- âœ… Fonctions de prÃ©traitement et feature engineering
- âœ… RÃ©sultats et Ã©tude de faisabilitÃ© (90.59% accuracy)
- âœ… Documentation README dÃ©taillÃ©e

### âœ… Interface de classification dÃ©ployable
- âœ… **Application Streamlit** : Classification via texte avec interface intuitive
- âœ… **API REST FastAPI** : Endpoints pour intÃ©gration backend
- âœ… Support de la classification textuelle (image en option)
- âœ… PrÃªt pour dÃ©ploiement cloud (Streamlit Cloud, Heroku)

### âœ… Tests et validation
- âœ… Test automatisÃ© du chargement des modÃ¨les
- âœ… Validation sur ensemble de test indÃ©pendant
- âœ… MÃ©triques complÃ¨tes (accuracy, F1, precision, recall)
- âœ… Interface testable immÃ©diatement

### ðŸ“Š RÃ©sultats de faisabilitÃ©

**Conclusion : âœ… FAISABLE avec excellentes performances**

| CritÃ¨re | RÃ©sultat | Statut |
|---------|----------|--------|
| Niveau de prÃ©cision | 90.59% | âœ… Excellent |
| F1-Score macro | 90.78% | âœ… Robuste |
| Nombre de classes | 56 catÃ©gories | âœ… Pertinent |
| Temps d'infÃ©rence | < 100ms | âœ… Production-ready |
| DÃ©ploiement | API + Web | âœ… OpÃ©rationnel |

**Recommandation :** Le moteur de classification est prÃªt pour la production avec d'excellentes performances sur 56 catÃ©gories principales.

## ðŸ“š RÃ©fÃ©rences

- [Scikit-learn Documentation](https://scikit-learn.org/)
- [TF-IDF Vectorization](https://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction)
- [Handling Imbalanced Data](https://imbalanced-learn.org/)
- [FastAPI Framework](https://fastapi.tiangolo.com/)
- [Streamlit Documentation](https://docs.streamlit.io/)

## ðŸ‘¥ Auteurs

Projet rÃ©alisÃ© dans le cadre du **Master IA - DIT**  
Classification de biens de consommation pour marketplace e-commerce

## ðŸ“„ Licence

Projet acadÃ©mique - Tous droits rÃ©servÃ©s
