# CLF04 â€” Classification de biens de consommation

## ğŸ“‹ Vue d'ensemble

Ce projet implÃ©mente un systÃ¨me de classification automatique pour catÃ©goriser des biens de consommation Ã  partir de donnÃ©es textuelles (nom, description, marque). L'objectif est d'automatiser l'attribution des produits Ã  des catÃ©gories pour optimiser l'expÃ©rience utilisateur sur une marketplace e-commerce.

## ğŸ“‚ Structure du projet

```
soutenance/
â”œâ”€â”€ classification_biens.ipynb    # Notebook principal avec pipeline complet
â”œâ”€â”€ dataset.csv                    # Dataset pour tests rapides  
â”œâ”€â”€ subject.md                     # Ã‰noncÃ© du projet
â”œâ”€â”€ README.md                      # Cette documentation
â”œâ”€â”€ api/
â”‚   â””â”€â”€ api_app.py                # API REST (FastAPI)
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ streamlit_app.py          # Interface web (Streamlit)
â”‚   â”œâ”€â”€ requirements.txt          # DÃ©pendances Python
â”‚   â”œâ”€â”€ README.md                 # Documentation de l'app
â”‚   â”œâ”€â”€ test_models.py            # Tests de chargement des modÃ¨les
â”‚   â”œâ”€â”€ run.sh                    # Script de lancement
â”‚   â”œâ”€â”€ Procfile                  # Configuration Heroku
â”‚   â””â”€â”€ .streamlit/
â”‚       â””â”€â”€ config.toml           # Configuration Streamlit
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ flipkart_com-ecommerce_sample_1050.csv  # Dataset principal
â”‚   â””â”€â”€ Images/                   # Images des produits (1050 fichiers)
â””â”€â”€ models/
    â”œâ”€â”€ logistic_regression_model.pkl    # ModÃ¨le entraÃ®nÃ© (413 classes)
    â””â”€â”€ tfidf_vectorizer.pkl             # Vectorizer TF-IDF (5000 features)
```

## ğŸš€ DÃ©marrage rapide

### PrÃ©requis
```bash
python >= 3.8
pip install pandas scikit-learn matplotlib seaborn jupyter
```

### ExÃ©cution du notebook

1. Ouvrir le notebook: `classification_biens.ipynb`
2. ExÃ©cuter les cellules dans l'ordre:
   - Configuration (cellule 1)
   - Import des bibliothÃ¨ques (cellule 2)
   - Chargement des donnÃ©es (cellule 3)
   - PrÃ©traitement et EDA (cellules 4-43)
   - EntraÃ®nement du modÃ¨le (cellules 56-57)
   - Visualisations (cellules 59-60)
   - Tests (cellules 62-64)

## ğŸ“Š Workflow du notebook

### 1. Configuration et importation
- DÃ©finition des rÃ©pertoires de travail
- Import des bibliothÃ¨ques (pandas, scikit-learn, matplotlib, etc.)
- Chargement du dataset Flipkart (1050 produits)

### 2. Analyse exploratoire des donnÃ©es (EDA)

**Variables:**
- NumÃ©riques: `retail_price`, `discounted_price`  
- CatÃ©gorielles: `product_name`, `description`, `brand`, `product_category_tree` (cible)
- Suppression des colonnes non pertinentes: `uniq_id`, `crawl_timestamp`, `pid`

**Imputation:**
- Prix: mÃ©diane
- Brand: "NoBrand"
- SpÃ©cifications: chaÃ®ne vide

**Visualisations:**
- Distributions univariÃ©es (histogrammes, boxplots)
- Distribution des catÃ©gories (trÃ¨s dÃ©sÃ©quilibrÃ©e)
- Analyses bivariÃ©es

### 3. PrÃ©paration des donnÃ©es

**Split stratifiÃ©:**
- Train: 60% (630 Ã©chantillons)
- Validation: 20% (210 Ã©chantillons)
- Test: 20% (210 Ã©chantillons)

**Feature engineering:**
- Combinaison de `product_name`, `description`, `brand` en une seule feature textuelle
- Vectorisation TF-IDF (5000 features, bigrammes, stop words anglais)

### 4. ModÃ©lisation

**ModÃ¨le baseline:**
- Algorithme: Logistic Regression
- Vectorization: TF-IDF
- HyperparamÃ¨tres: max_iter=1000, random_state=42

**RÃ©sultats:**
```
Validation:
  Accuracy: 0.2095 (20.95%)
  F1 macro: 0.0760 (7.60%)

Test:
  Accuracy: 0.1905 (19.05%)
  F1 macro: 0.0717 (7.17%)
```

### 5. Visualisations et mÃ©triques

- Distribution des classes (graphique Ã  barres)
- Matrice de confusion (heatmap)
- Rapport de classification dÃ©taillÃ© (precision, recall, F1-score par classe)

### 6. Tests et validation

- **Test 1:** PrÃ©dictions sur exemples du test set
- **Test 2:** Fonction de prÃ©diction personnalisÃ©e avec top-3 catÃ©gories
- **Test 3:** Comparaison avec baseline alÃ©atoire

### 7. Sauvegarde

ModÃ¨les sauvegardÃ©s dans `/models`:
- `logistic_regression_model.pkl`  
- `tfidf_vectorizer.pkl`

## ğŸ“ˆ RÃ©sultats et analyses

### Points forts
âœ“ Pipeline complet de bout en bout fonctionnel
âœ“ PrÃ©traitement robuste des donnÃ©es textuelles
âœ“ ModÃ¨le baseline simple et interprÃ©table
âœ“ Sauvegarde des modÃ¨les pour rÃ©utilisation

### Limitations
âš ï¸ Performance modeste due Ã :
- Fort dÃ©sÃ©quilibre des classes (distribution trÃ¨s asymÃ©trique)
- Nombreuses catÃ©gories avec peu d'exemples
- Features textuelles basiques (TF-IDF)
- ModÃ¨le linÃ©aire simple

### AmÃ©liorations possibles

**1. Traitement du dÃ©sÃ©quilibre de classes:**
- SMOTE (Synthetic Minority Over-sampling)
- Class weights dans le modÃ¨le
- StratÃ©gies d'Ã©chantillonnage

**2. ModÃ¨les plus avancÃ©s:**
- Random Forest / XGBoost / CatBoost
- Deep Learning: LSTM, Transformers
- Embeddings prÃ©-entraÃ®nÃ©s: BERT, DistilBERT, Sentence-BERT

**3. Feature Engineering avancÃ©:**
- Extraction de features numÃ©riques (longueur, nb mots, etc.)
- Utilisation des spÃ©cifications produit
- Analyse des images (CNN, Vision Transformers)
- Features basÃ©es sur les prix

**4. Optimisation:**
- Grid Search / Random Search / Bayesian Optimization
- Cross-validation stratifiÃ©e
- Ensembling (voting, stacking)

**5. Ã‰valuation:**
- MÃ©triques adaptÃ©es au dÃ©sÃ©quilibre (macro F1, weighted F1)
- Courbes ROC multiclasses
- Analyse des erreurs par catÃ©gorie

## ğŸŒ DÃ©ploiement

### API REST (FastAPI)

L'API FastAPI fournit une interface REST complÃ¨te pour la classification de produits.

**Lancement:**
```bash
cd api
python api_app.py
# OU utiliser le script
./run.sh
```

L'API sera disponible sur:
- **API**: http://localhost:8000
- **Documentation Swagger**: http://localhost:8000/docs
- **Documentation ReDoc**: http://localhost:8000/redoc

**Endpoints principaux:**

**GET** `/health` - VÃ©rification de l'Ã©tat de santÃ©
```bash
curl http://localhost:8000/health
```

**POST** `/predict` - PrÃ©diction complÃ¨te avec mÃ©tadonnÃ©es
```bash
curl -X POST "http://localhost:8000/predict" \
  -H "Content-Type: application/json" \
  -d '{
    "product_name": "Nike Running Shoes",
    "description": "Comfortable running shoes",
    "brand": "Nike"
  }'
```

**POST** `/predict/simple` - PrÃ©diction rapide (form data)
```bash
curl -X POST "http://localhost:8000/predict/simple" \
  -F "text=Nike running shoes for men"
```

**POST** `/batch-predict` - PrÃ©diction par lot
```bash
curl -X POST "http://localhost:8000/batch-predict" \
  -H "Content-Type: application/json" \
  -d '{
    "products": [
      {"description": "Nike shoes"},
      {"description": "Cotton bedsheet"}
    ],
    "top_k": 3
  }'
```

**GET** `/models/info` - Informations sur les modÃ¨les

**FonctionnalitÃ©s de l'API:**
- âœ… Documentation interactive (Swagger UI + ReDoc)
- âœ… Validation automatique des donnÃ©es (Pydantic)
- âœ… Gestion d'erreurs robuste
- âœ… Support CORS
- âœ… Logging dÃ©taillÃ©
- âœ… Cache des modÃ¨les en mÃ©moire
- âœ… Top-K prÃ©dictions avec probabilitÃ©s
- âœ… MÃ©tadonnÃ©es de performance
- âœ… PrÃ©dictions par lot
- âœ… Endpoints de monitoring

**Test de l'API:**
```bash
# Tests automatisÃ©s
cd api
python test_api.py

# Exemples avec curl
./examples.sh

# Client Python
python client_example.py
```

**DÃ©ploiement:**
- Docker: `docker build -t clf04-api . && docker run -p 8000:8000 clf04-api`
- Production: `gunicorn api_app:app -w 4 -k uvicorn.workers.UvicornWorker`
- Heroku: `git push heroku main` (Procfile configurÃ©)

### Interface Streamlit

L'application Streamlit offre une interface conviviale pour tester le modÃ¨le de classification.

**Lancement:**
```bash
cd app
streamlit run streamlit_app.py
# OU utiliser le script de lancement
./run.sh
```
L'interface s'ouvre automatiquement sur `http://localhost:8501`

**FonctionnalitÃ©s principales:**

**ğŸ“ Onglet Classification Textuelle:**
- Formulaire intuitif pour saisir le nom, description et marque du produit
- Exemples prÃ©dÃ©finis pour test rapide
- Affichage de la catÃ©gorie prÃ©dite avec niveau de confiance
- Top 5 des prÃ©dictions avec probabilitÃ©s
- Graphique interactif des rÃ©sultats
- Support pour texte en anglais

**ğŸ–¼ï¸ Onglet Classification par Image:**
- Upload d'images (JPG, JPEG, PNG)
- Extraction automatique de features avec ResNet50
- AperÃ§u de l'image tÃ©lÃ©chargÃ©e
- Exemples d'images du dataset
- Note: NÃ©cessite TensorFlow installÃ©

**â„¹ï¸ Onglet Ã€ propos:**
- Documentation du projet
- Statistiques et mÃ©triques
- Technologies utilisÃ©es
- Guide d'utilisation
- Roadmap des amÃ©liorations

**Interface:**
- Design moderne et responsive
- ThÃ¨me personnalisÃ© avec couleurs cohÃ©rentes
- Navigation par onglets
- Sidebar avec informations en temps rÃ©el
- Messages d'erreur explicites
- Mise en cache des modÃ¨les pour performances optimales

**Installation des dÃ©pendances:**
```bash
cd app
pip install -r requirements.txt
```

**DÃ©ploiement sur le cloud:**
- Streamlit Cloud: Push sur GitHub et dÃ©ployer via streamlit.io
- Heroku: Utiliser le `Procfile` fourni
- Docker: Container prÃªt Ã  l'emploi (voir app/README.md)

**Test du systÃ¨me:**
```bash
cd app
python test_models.py  # VÃ©rifie que les modÃ¨les sont chargÃ©s correctement
```

## ğŸ“ Notes techniques

**Dataset:**
- Source: Flipkart e-commerce
- Taille: 1050 produits
- Classes: ~800+ catÃ©gories distinctes (trÃ¨s dÃ©sÃ©quilibrÃ©)
- Langue: Anglais

**Environnement:**
- Python 3.13
- Jupyter Notebook
- Anaconda environment

**DÃ©pendances principales:**
```
# Core
pandas==2.2.3
numpy==1.26.4  # Compatible avec TensorFlow 2.16
scikit-learn==1.7.1

# Visualisation
matplotlib==3.10.0
seaborn==0.13.2

# Web & Interface
streamlit>=1.28.0
fastapi
uvicorn

# Deep Learning (optionnel)
tensorflow==2.16.0
pillow>=10.0.0
```

**Installation complÃ¨te:**
```bash
# Pour le notebook et l'entraÃ®nement
pip install pandas numpy scikit-learn matplotlib seaborn jupyter

# Pour l'application Streamlit
cd app
pip install -r requirements.txt

# Pour le support image (optionnel)
pip install tensorflow==2.16.0 pillow
```

## ğŸ“š RÃ©fÃ©rences

- [Scikit-learn Documentation](https://scikit-learn.org/)
- [TF-IDF Vectorization](https://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction)
- [Handling Imbalanced Data](https://imbalanced-learn.org/)

## ğŸ‘¥ Auteurs

Projet rÃ©alisÃ© dans le cadre du Master IA - DIT

## ğŸ“„ Licence

Projet acadÃ©mique - Tous droits rÃ©servÃ©s
